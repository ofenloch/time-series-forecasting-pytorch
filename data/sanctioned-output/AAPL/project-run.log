All libraries loaded
config["alpha_vantage"]["datafile"] is data/alphavantage_TIME_SERIES_DAILY_ADJUSTED__AAPL__data.json
*********** TEST MODE ***********
     disabling all randomness
*********** TEST MODE ***********
Number data points 6333 from 1999-11-01 to 2025-01-02
Train data shape (5050, 20, 1) (5050,)
Validation data shape (1263, 20, 1) (1263,)
Epoch[1/100] | loss train:0.016085, test:0.699678 | lr:0.010000
Epoch[2/100] | loss train:0.001774, test:0.657898 | lr:0.010000
Epoch[3/100] | loss train:0.001257, test:0.464883 | lr:0.010000
Epoch[4/100] | loss train:0.001146, test:0.495316 | lr:0.010000
Epoch[5/100] | loss train:0.000893, test:0.479221 | lr:0.010000
Epoch[6/100] | loss train:0.000632, test:0.488687 | lr:0.010000
Epoch[7/100] | loss train:0.000830, test:0.428485 | lr:0.010000
Epoch[8/100] | loss train:0.000707, test:0.450385 | lr:0.010000
Epoch[9/100] | loss train:0.000670, test:0.410539 | lr:0.010000
Epoch[10/100] | loss train:0.000559, test:0.383582 | lr:0.010000
Epoch[11/100] | loss train:0.000594, test:0.355062 | lr:0.010000
Epoch[12/100] | loss train:0.000593, test:0.290374 | lr:0.010000
Epoch[13/100] | loss train:0.000697, test:0.412945 | lr:0.010000
Epoch[14/100] | loss train:0.000533, test:0.398855 | lr:0.010000
Epoch[15/100] | loss train:0.000580, test:0.286704 | lr:0.010000
Epoch[16/100] | loss train:0.000529, test:0.329723 | lr:0.010000
Epoch[17/100] | loss train:0.000557, test:0.328524 | lr:0.010000
Epoch[18/100] | loss train:0.000609, test:0.343672 | lr:0.010000
Epoch[19/100] | loss train:0.000639, test:0.428095 | lr:0.010000
Epoch[20/100] | loss train:0.000576, test:0.330933 | lr:0.010000
Epoch[21/100] | loss train:0.000489, test:0.347044 | lr:0.010000
Epoch[22/100] | loss train:0.000503, test:0.370886 | lr:0.010000
Epoch[23/100] | loss train:0.000567, test:0.409569 | lr:0.010000
Epoch[24/100] | loss train:0.000499, test:0.389539 | lr:0.010000
Epoch[25/100] | loss train:0.000521, test:0.392651 | lr:0.010000
Epoch[26/100] | loss train:0.000531, test:0.313024 | lr:0.010000
Epoch[27/100] | loss train:0.000563, test:0.410343 | lr:0.010000
Epoch[28/100] | loss train:0.000515, test:0.351096 | lr:0.010000
Epoch[29/100] | loss train:0.000516, test:0.376792 | lr:0.010000
Epoch[30/100] | loss train:0.000559, test:0.401614 | lr:0.010000
Epoch[31/100] | loss train:0.000547, test:0.352262 | lr:0.010000
Epoch[32/100] | loss train:0.000571, test:0.515414 | lr:0.010000
Epoch[33/100] | loss train:0.000490, test:0.394159 | lr:0.010000
Epoch[34/100] | loss train:0.000770, test:0.389995 | lr:0.010000
Epoch[35/100] | loss train:0.000517, test:0.410864 | lr:0.010000
Epoch[36/100] | loss train:0.000482, test:0.425466 | lr:0.010000
Epoch[37/100] | loss train:0.000540, test:0.441560 | lr:0.010000
Epoch[38/100] | loss train:0.000507, test:0.454576 | lr:0.010000
Epoch[39/100] | loss train:0.000553, test:0.507377 | lr:0.010000
Epoch[40/100] | loss train:0.000499, test:0.462921 | lr:0.010000
Epoch[41/100] | loss train:0.000427, test:0.441151 | lr:0.001000
Epoch[42/100] | loss train:0.000377, test:0.442580 | lr:0.001000
Epoch[43/100] | loss train:0.000373, test:0.450739 | lr:0.001000
Epoch[44/100] | loss train:0.000404, test:0.424338 | lr:0.001000
Epoch[45/100] | loss train:0.000378, test:0.440317 | lr:0.001000
Epoch[46/100] | loss train:0.000364, test:0.419980 | lr:0.001000
Epoch[47/100] | loss train:0.000381, test:0.442813 | lr:0.001000
Epoch[48/100] | loss train:0.000357, test:0.434902 | lr:0.001000
Epoch[49/100] | loss train:0.000413, test:0.435726 | lr:0.001000
Epoch[50/100] | loss train:0.000368, test:0.442253 | lr:0.001000
Epoch[51/100] | loss train:0.000377, test:0.387400 | lr:0.001000
Epoch[52/100] | loss train:0.000387, test:0.431963 | lr:0.001000
Epoch[53/100] | loss train:0.000397, test:0.434637 | lr:0.001000
Epoch[54/100] | loss train:0.000374, test:0.433615 | lr:0.001000
Epoch[55/100] | loss train:0.000378, test:0.427785 | lr:0.001000
Epoch[56/100] | loss train:0.000396, test:0.419377 | lr:0.001000
Epoch[57/100] | loss train:0.000370, test:0.450428 | lr:0.001000
Epoch[58/100] | loss train:0.000378, test:0.459985 | lr:0.001000
Epoch[59/100] | loss train:0.000392, test:0.460566 | lr:0.001000
Epoch[60/100] | loss train:0.000379, test:0.437083 | lr:0.001000
Epoch[61/100] | loss train:0.000384, test:0.436480 | lr:0.001000
Epoch[62/100] | loss train:0.000357, test:0.434412 | lr:0.001000
Epoch[63/100] | loss train:0.000359, test:0.445789 | lr:0.001000
Epoch[64/100] | loss train:0.000365, test:0.415158 | lr:0.001000
Epoch[65/100] | loss train:0.000350, test:0.470521 | lr:0.001000
Epoch[66/100] | loss train:0.000365, test:0.421939 | lr:0.001000
Epoch[67/100] | loss train:0.000341, test:0.427901 | lr:0.001000
Epoch[68/100] | loss train:0.000366, test:0.422296 | lr:0.001000
Epoch[69/100] | loss train:0.000372, test:0.402202 | lr:0.001000
Epoch[70/100] | loss train:0.000357, test:0.430684 | lr:0.001000
Epoch[71/100] | loss train:0.000381, test:0.438993 | lr:0.001000
Epoch[72/100] | loss train:0.000390, test:0.467611 | lr:0.001000
Epoch[73/100] | loss train:0.000373, test:0.509035 | lr:0.001000
Epoch[74/100] | loss train:0.000373, test:0.449856 | lr:0.001000
Epoch[75/100] | loss train:0.000358, test:0.448621 | lr:0.001000
Epoch[76/100] | loss train:0.000368, test:0.437891 | lr:0.001000
Epoch[77/100] | loss train:0.000373, test:0.487858 | lr:0.001000
Epoch[78/100] | loss train:0.000358, test:0.497799 | lr:0.001000
Epoch[79/100] | loss train:0.000379, test:0.432818 | lr:0.001000
Epoch[80/100] | loss train:0.000377, test:0.439949 | lr:0.001000
Epoch[81/100] | loss train:0.000334, test:0.446957 | lr:0.000100
Epoch[82/100] | loss train:0.000344, test:0.458452 | lr:0.000100
Epoch[83/100] | loss train:0.000360, test:0.456978 | lr:0.000100
Epoch[84/100] | loss train:0.000342, test:0.452305 | lr:0.000100
Epoch[85/100] | loss train:0.000362, test:0.459343 | lr:0.000100
Epoch[86/100] | loss train:0.000355, test:0.449990 | lr:0.000100
Epoch[87/100] | loss train:0.000346, test:0.455076 | lr:0.000100
Epoch[88/100] | loss train:0.000338, test:0.470871 | lr:0.000100
Epoch[89/100] | loss train:0.000368, test:0.467205 | lr:0.000100
Epoch[90/100] | loss train:0.000355, test:0.461349 | lr:0.000100
Epoch[91/100] | loss train:0.000346, test:0.466140 | lr:0.000100
Epoch[92/100] | loss train:0.000355, test:0.470903 | lr:0.000100
Epoch[93/100] | loss train:0.000359, test:0.467114 | lr:0.000100
Epoch[94/100] | loss train:0.000345, test:0.465044 | lr:0.000100
Epoch[95/100] | loss train:0.000329, test:0.463724 | lr:0.000100
Epoch[96/100] | loss train:0.000377, test:0.472172 | lr:0.000100
Epoch[97/100] | loss train:0.000342, test:0.458523 | lr:0.000100
Epoch[98/100] | loss train:0.000363, test:0.466819 | lr:0.000100
Epoch[99/100] | loss train:0.000326, test:0.456628 | lr:0.000100
Epoch[100/100] | loss train:0.000352, test:0.463057 | lr:0.000100
Predicted close price of the next trading day: 97.68
