All libraries loaded
config["alpha_vantage"]["datafile"] is data/alphavantage_TIME_SERIES_DAILY_ADJUSTED__DOGG__data.json
*********** TEST MODE ***********
     disabling all randomness
*********** TEST MODE ***********
Number data points 424 from 2023-04-27 to 2025-01-02
Train data shape (323, 20, 1) (323,)
Validation data shape (81, 20, 1) (81,)
Epoch[1/100] | loss train:0.095871, test:0.026429 | lr:0.010000
Epoch[2/100] | loss train:0.040278, test:0.022598 | lr:0.010000
Epoch[3/100] | loss train:0.010606, test:0.017971 | lr:0.010000
Epoch[4/100] | loss train:0.017819, test:0.005672 | lr:0.010000
Epoch[5/100] | loss train:0.022618, test:0.005109 | lr:0.010000
Epoch[6/100] | loss train:0.014342, test:0.017785 | lr:0.010000
Epoch[7/100] | loss train:0.014395, test:0.005610 | lr:0.010000
Epoch[8/100] | loss train:0.023884, test:0.007815 | lr:0.010000
Epoch[9/100] | loss train:0.008280, test:0.004879 | lr:0.010000
Epoch[10/100] | loss train:0.020198, test:0.005770 | lr:0.010000
Epoch[11/100] | loss train:0.006139, test:0.004588 | lr:0.010000
Epoch[12/100] | loss train:0.013297, test:0.006109 | lr:0.010000
Epoch[13/100] | loss train:0.016170, test:0.012436 | lr:0.010000
Epoch[14/100] | loss train:0.007223, test:0.003918 | lr:0.010000
Epoch[15/100] | loss train:0.009483, test:0.008304 | lr:0.010000
Epoch[16/100] | loss train:0.020638, test:0.004533 | lr:0.010000
Epoch[17/100] | loss train:0.006234, test:0.002754 | lr:0.010000
Epoch[18/100] | loss train:0.009169, test:0.004181 | lr:0.010000
Epoch[19/100] | loss train:0.004819, test:0.002570 | lr:0.010000
Epoch[20/100] | loss train:0.018697, test:0.005455 | lr:0.010000
Epoch[21/100] | loss train:0.021740, test:0.004742 | lr:0.010000
Epoch[22/100] | loss train:0.004546, test:0.004703 | lr:0.010000
Epoch[23/100] | loss train:0.010834, test:0.001977 | lr:0.010000
Epoch[24/100] | loss train:0.014193, test:0.004817 | lr:0.010000
Epoch[25/100] | loss train:0.022733, test:0.005293 | lr:0.010000
Epoch[26/100] | loss train:0.023155, test:0.007837 | lr:0.010000
Epoch[27/100] | loss train:0.010301, test:0.002209 | lr:0.010000
Epoch[28/100] | loss train:0.003982, test:0.004498 | lr:0.010000
Epoch[29/100] | loss train:0.004400, test:0.003287 | lr:0.010000
Epoch[30/100] | loss train:0.006856, test:0.002416 | lr:0.010000
Epoch[31/100] | loss train:0.003130, test:0.004963 | lr:0.010000
Epoch[32/100] | loss train:0.046390, test:0.003112 | lr:0.010000
Epoch[33/100] | loss train:0.008895, test:0.010254 | lr:0.010000
Epoch[34/100] | loss train:0.020468, test:0.003252 | lr:0.010000
Epoch[35/100] | loss train:0.006908, test:0.004085 | lr:0.010000
Epoch[36/100] | loss train:0.006816, test:0.001033 | lr:0.010000
Epoch[37/100] | loss train:0.008357, test:0.004247 | lr:0.010000
Epoch[38/100] | loss train:0.005325, test:0.001765 | lr:0.010000
Epoch[39/100] | loss train:0.003757, test:0.002095 | lr:0.010000
Epoch[40/100] | loss train:0.011949, test:0.004212 | lr:0.010000
Epoch[41/100] | loss train:0.022489, test:0.002367 | lr:0.001000
Epoch[42/100] | loss train:0.004374, test:0.004783 | lr:0.001000
Epoch[43/100] | loss train:0.006050, test:0.004103 | lr:0.001000
Epoch[44/100] | loss train:0.014771, test:0.003490 | lr:0.001000
Epoch[45/100] | loss train:0.013402, test:0.003369 | lr:0.001000
Epoch[46/100] | loss train:0.005010, test:0.001825 | lr:0.001000
Epoch[47/100] | loss train:0.009142, test:0.002885 | lr:0.001000
Epoch[48/100] | loss train:0.004960, test:0.003156 | lr:0.001000
Epoch[49/100] | loss train:0.003892, test:0.003967 | lr:0.001000
Epoch[50/100] | loss train:0.014932, test:0.002710 | lr:0.001000
Epoch[51/100] | loss train:0.006133, test:0.003000 | lr:0.001000
Epoch[52/100] | loss train:0.005747, test:0.003258 | lr:0.001000
Epoch[53/100] | loss train:0.003590, test:0.002368 | lr:0.001000
Epoch[54/100] | loss train:0.006139, test:0.003260 | lr:0.001000
Epoch[55/100] | loss train:0.012085, test:0.002891 | lr:0.001000
Epoch[56/100] | loss train:0.009013, test:0.004215 | lr:0.001000
Epoch[57/100] | loss train:0.015215, test:0.003296 | lr:0.001000
Epoch[58/100] | loss train:0.011178, test:0.002842 | lr:0.001000
Epoch[59/100] | loss train:0.005575, test:0.003344 | lr:0.001000
Epoch[60/100] | loss train:0.005625, test:0.003545 | lr:0.001000
Epoch[61/100] | loss train:0.002433, test:0.004842 | lr:0.001000
Epoch[62/100] | loss train:0.006385, test:0.002017 | lr:0.001000
Epoch[63/100] | loss train:0.006062, test:0.001848 | lr:0.001000
Epoch[64/100] | loss train:0.010976, test:0.004174 | lr:0.001000
Epoch[65/100] | loss train:0.007020, test:0.003336 | lr:0.001000
Epoch[66/100] | loss train:0.007365, test:0.002525 | lr:0.001000
Epoch[67/100] | loss train:0.005190, test:0.002511 | lr:0.001000
Epoch[68/100] | loss train:0.010383, test:0.002168 | lr:0.001000
Epoch[69/100] | loss train:0.007410, test:0.004401 | lr:0.001000
Epoch[70/100] | loss train:0.008459, test:0.005734 | lr:0.001000
Epoch[71/100] | loss train:0.012856, test:0.003515 | lr:0.001000
Epoch[72/100] | loss train:0.010532, test:0.003319 | lr:0.001000
Epoch[73/100] | loss train:0.007538, test:0.003915 | lr:0.001000
Epoch[74/100] | loss train:0.014589, test:0.003947 | lr:0.001000
Epoch[75/100] | loss train:0.006034, test:0.003197 | lr:0.001000
Epoch[76/100] | loss train:0.002591, test:0.003225 | lr:0.001000
Epoch[77/100] | loss train:0.017102, test:0.003451 | lr:0.001000
Epoch[78/100] | loss train:0.007814, test:0.003867 | lr:0.001000
Epoch[79/100] | loss train:0.011672, test:0.003214 | lr:0.001000
Epoch[80/100] | loss train:0.006362, test:0.003540 | lr:0.001000
Epoch[81/100] | loss train:0.010826, test:0.003086 | lr:0.000100
Epoch[82/100] | loss train:0.007493, test:0.003105 | lr:0.000100
Epoch[83/100] | loss train:0.013989, test:0.003396 | lr:0.000100
Epoch[84/100] | loss train:0.004863, test:0.002443 | lr:0.000100
Epoch[85/100] | loss train:0.016876, test:0.002060 | lr:0.000100
Epoch[86/100] | loss train:0.006980, test:0.003323 | lr:0.000100
Epoch[87/100] | loss train:0.006361, test:0.001900 | lr:0.000100
Epoch[88/100] | loss train:0.005791, test:0.002985 | lr:0.000100
Epoch[89/100] | loss train:0.007455, test:0.004555 | lr:0.000100
Epoch[90/100] | loss train:0.014359, test:0.003869 | lr:0.000100
Epoch[91/100] | loss train:0.006412, test:0.003990 | lr:0.000100
Epoch[92/100] | loss train:0.004685, test:0.003706 | lr:0.000100
Epoch[93/100] | loss train:0.015920, test:0.002345 | lr:0.000100
Epoch[94/100] | loss train:0.006376, test:0.003179 | lr:0.000100
Epoch[95/100] | loss train:0.012160, test:0.002882 | lr:0.000100
Epoch[96/100] | loss train:0.010439, test:0.002145 | lr:0.000100
Epoch[97/100] | loss train:0.004589, test:0.002379 | lr:0.000100
Epoch[98/100] | loss train:0.015578, test:0.002522 | lr:0.000100
Epoch[99/100] | loss train:0.006455, test:0.003150 | lr:0.000100
Epoch[100/100] | loss train:0.009011, test:0.003597 | lr:0.000100
Predicted close price of the next trading day: 19.07
